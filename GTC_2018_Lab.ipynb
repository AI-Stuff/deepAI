{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## \"Detection of Anomalies in Financial Transactions using Deep Autoencoder Networks\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This GPU Technology Conference (GTC) 2018 lab was developed by Mr. X, and Mr. Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. Environment Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 01.1 Python Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin, let's verify that Python is working on your system. To do this, execute the cell block below by giving it focus (clicking on it with your mouse), and hitting Shift-Enter, or pressing the play button in the toolbar above. If all goes well, you should see some output returned below the grey cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer should be forty-two: 42\n"
     ]
    }
   ],
   "source": [
    "print(\"The answer should be forty-two: \" + str(40+2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 01.2 CUDNN / GPU Verficiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PT LOG TRAIN 20180124-15:17:49] CUDNN backend version: None\n"
     ]
    }
   ],
   "source": [
    "# print CUDNN backend version\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "print('[LOG TRAIN {}] CUDNN backend version: {}'.format(now, torch.backends.cudnn.version()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's execute the cell below to display information about the GPUs running on the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: nvidia-smi: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 01.3 Import Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing utilities\n",
    "import os\n",
    "from datetime import datetime\n",
    "from IPython.display import Image\n",
    "\n",
    "# importing pytorch libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import autograd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# importing data science libraries\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20180124-15:19:31] PyTorch version: 0.3.0.post4\n"
     ]
    }
   ],
   "source": [
    "# print current PyTorch version\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "print('[LOG TRAIN {}] PyTorch version: {}'.format(now, torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. Lab Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDo -- Timur and Marco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"middle\" style=\"max-width: 550px; height: auto\" src=\"images/accounting.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. Autoencoder Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 03.1 Introduction to Autoencoder Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"middle\" style=\"max-width: 600px; height: auto\" src=\"images/autoencoder.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 03.2 Implementing the Encoder Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class encoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(encoder, self).__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.0, inplace=True)\n",
    "\n",
    "        self.encoder_L1 = nn.Linear(401, 512, bias=True)\n",
    "        nn.init.xavier_uniform(self.encoder_L1.weight)\n",
    "        self.encoder_R1 = nn.LeakyReLU(negative_slope= 0.4, inplace=True)\n",
    "\n",
    "        self.encoder_L2 = nn.Linear(512, 256, bias=True)\n",
    "        nn.init.xavier_uniform(self.encoder_L2.weight)\n",
    "        self.encoder_R2 = nn.LeakyReLU(negative_slope= 0.4, inplace=True)\n",
    "\n",
    "        self.encoder_L3 = nn.Linear(256, 128, bias=True)\n",
    "        nn.init.xavier_uniform(self.encoder_L3.weight)\n",
    "        self.encoder_R3 = nn.LeakyReLU(negative_slope= 0.4, inplace=True)\n",
    "\n",
    "        self.encoder_L4 = nn.Linear(128, 64, bias=True)\n",
    "        nn.init.xavier_uniform(self.encoder_L4.weight)\n",
    "        self.encoder_R4 = nn.LeakyReLU(negative_slope= 0.4, inplace=True)\n",
    "\n",
    "        self.encoder_L5 = nn.Linear(64, 32, bias=True)\n",
    "        nn.init.xavier_uniform(self.encoder_L5.weight)\n",
    "        self.encoder_R5 = nn.LeakyReLU(negative_slope= 0.4, inplace=True)\n",
    "\n",
    "        self.encoder_L6 = nn.Linear(32, 16, bias=True)\n",
    "        nn.init.xavier_uniform(self.encoder_L6.weight)\n",
    "        self.encoder_R6 = nn.LeakyReLU(negative_slope= 0.4, inplace=True)\n",
    "\n",
    "        self.encoder_L7 = nn.Linear(16, 8, bias=True)\n",
    "        nn.init.xavier_uniform(self.encoder_L7.weight)\n",
    "        self.encoder_R7 = nn.LeakyReLU(negative_slope= 0.4, inplace=True)\n",
    "\n",
    "        self.encoder_L8 = nn.Linear(8, 4, bias=True)\n",
    "        nn.init.xavier_uniform(self.encoder_L8.weight)\n",
    "        self.encoder_R8 = nn.LeakyReLU(negative_slope= 0.4, inplace=True)\n",
    "\n",
    "        self.encoder_L9 = nn.Linear(4, 3, bias=True)\n",
    "        nn.init.xavier_uniform(self.encoder_L9.weight)\n",
    "        self.encoder_R9 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.encoder_R1(self.dropout(self.encoder_L1(x)))\n",
    "        x = self.encoder_R2(self.dropout(self.encoder_L2(x)))\n",
    "        x = self.encoder_R3(self.dropout(self.encoder_L3(x)))\n",
    "        x = self.encoder_R4(self.dropout(self.encoder_L4(x)))\n",
    "        x = self.encoder_R5(self.dropout(self.encoder_L5(x)))\n",
    "        x = self.encoder_R6(self.dropout(self.encoder_L6(x)))\n",
    "        x = self.encoder_R7(self.dropout(self.encoder_L7(x)))\n",
    "        x = self.encoder_R8(self.dropout(self.encoder_L8(x)))\n",
    "        x = self.encoder_R9(self.encoder_L9(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 03.3 Implementing the Decoder Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class decoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(decoder, self).__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.0, inplace=True)\n",
    "\n",
    "        self.decoder_L1 = nn.Linear(3, 4, bias=True)\n",
    "        nn.init.xavier_uniform(self.decoder_L1.weight)\n",
    "        self.decoder_R1 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        self.decoder_L2 = nn.Linear(4, 8, bias=True)\n",
    "        nn.init.xavier_uniform(self.decoder_L2.weight)\n",
    "        self.decoder_R2 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        self.decoder_L3 = nn.Linear(8, 16, bias=True)\n",
    "        nn.init.xavier_uniform(self.decoder_L3.weight)\n",
    "        self.decoder_R3 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        self.decoder_L4 = nn.Linear(16, 32, bias=True)\n",
    "        nn.init.xavier_uniform(self.decoder_L4.weight)\n",
    "        self.decoder_R4 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        self.decoder_L5 = nn.Linear(32, 64, bias=True)\n",
    "        nn.init.xavier_uniform(self.decoder_L5.weight)\n",
    "        self.decoder_R5 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        self.decoder_L6 = nn.Linear(64, 128, bias=True)\n",
    "        nn.init.xavier_uniform(self.decoder_L6.weight)\n",
    "        self.decoder_R6 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        self.decoder_L7 = nn.Linear(128, 256, bias=True)\n",
    "        nn.init.xavier_uniform(self.decoder_L7.weight)\n",
    "        self.decoder_R7 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        self.decoder_L8 = nn.Linear(256, 512, bias=True)\n",
    "        nn.init.xavier_uniform(self.decoder_L8.weight)\n",
    "        self.decoder_R8 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        self.decoder_L9 = nn.Linear(512, 401, bias=True)\n",
    "        nn.init.xavier_uniform(self.decoder_L9.weight)\n",
    "        self.decoder_R9 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.decoder_R1(self.dropout(self.decoder_L1(x)))\n",
    "        x = self.decoder_R2(self.dropout(self.decoder_L2(x)))\n",
    "        x = self.decoder_R3(self.dropout(self.decoder_L3(x)))\n",
    "        x = self.decoder_R4(self.dropout(self.decoder_L4(x)))\n",
    "        x = self.decoder_R5(self.dropout(self.decoder_L5(x)))\n",
    "        x = self.decoder_R6(self.dropout(self.decoder_L6(x)))\n",
    "        x = self.decoder_R7(self.dropout(self.decoder_L7(x)))\n",
    "        x = self.decoder_R8(self.dropout(self.decoder_L8(x)))\n",
    "        x = self.decoder_R9(self.decoder_L9(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# init the encoder and decoder architectures\n",
    "encoder = encoder()\n",
    "decoder = decoder()\n",
    "\n",
    "# push to cuda if cudnn is available\n",
    "if (torch.backends.cudnn.version() != None):\n",
    "    encoder = encoder().cuda()\n",
    "    decoder = decoder().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG 20180124-15:12:42] encoder architecture:\n",
      "\n",
      "encoder(\n",
      "  (dropout): Dropout(p=0.0, inplace)\n",
      "  (encoder_L1): Linear(in_features=401, out_features=512)\n",
      "  (encoder_R1): LeakyReLU(0.4, inplace)\n",
      "  (encoder_L2): Linear(in_features=512, out_features=256)\n",
      "  (encoder_R2): LeakyReLU(0.4, inplace)\n",
      "  (encoder_L3): Linear(in_features=256, out_features=128)\n",
      "  (encoder_R3): LeakyReLU(0.4, inplace)\n",
      "  (encoder_L4): Linear(in_features=128, out_features=64)\n",
      "  (encoder_R4): LeakyReLU(0.4, inplace)\n",
      "  (encoder_L5): Linear(in_features=64, out_features=32)\n",
      "  (encoder_R5): LeakyReLU(0.4, inplace)\n",
      "  (encoder_L6): Linear(in_features=32, out_features=16)\n",
      "  (encoder_R6): LeakyReLU(0.4, inplace)\n",
      "  (encoder_L7): Linear(in_features=16, out_features=8)\n",
      "  (encoder_R7): LeakyReLU(0.4, inplace)\n",
      "  (encoder_L8): Linear(in_features=8, out_features=4)\n",
      "  (encoder_R8): LeakyReLU(0.4, inplace)\n",
      "  (encoder_L9): Linear(in_features=4, out_features=3)\n",
      "  (encoder_R9): LeakyReLU(0.4, inplace)\n",
      ")\n",
      "\n",
      "[LOG 20180124-15:12:42] decoder architecture:\n",
      "\n",
      "decoder(\n",
      "  (dropout): Dropout(p=0.0, inplace)\n",
      "  (decoder_L1): Linear(in_features=3, out_features=4)\n",
      "  (decoder_R1): LeakyReLU(0.4, inplace)\n",
      "  (decoder_L2): Linear(in_features=4, out_features=8)\n",
      "  (decoder_R2): LeakyReLU(0.4, inplace)\n",
      "  (decoder_L3): Linear(in_features=8, out_features=16)\n",
      "  (decoder_R3): LeakyReLU(0.4, inplace)\n",
      "  (decoder_L4): Linear(in_features=16, out_features=32)\n",
      "  (decoder_R4): LeakyReLU(0.4, inplace)\n",
      "  (decoder_L5): Linear(in_features=32, out_features=64)\n",
      "  (decoder_R5): LeakyReLU(0.4, inplace)\n",
      "  (decoder_L6): Linear(in_features=64, out_features=128)\n",
      "  (decoder_R6): LeakyReLU(0.4, inplace)\n",
      "  (decoder_L7): Linear(in_features=128, out_features=256)\n",
      "  (decoder_R7): LeakyReLU(0.4, inplace)\n",
      "  (decoder_L8): Linear(in_features=256, out_features=512)\n",
      "  (decoder_R8): LeakyReLU(0.4, inplace)\n",
      "  (decoder_L9): Linear(in_features=512, out_features=401)\n",
      "  (decoder_R9): LeakyReLU(0.4, inplace)\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the initialized architectures\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "print('[LOG {}] encoder architecture:\\n\\n{}\\n'.format(now, encoder))\n",
    "print('[LOG {}] decoder architecture:\\n\\n{}\\n'.format(now, decoder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. Financial Fraud Detection Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDo -- Timur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PT LOG 20180124-15:24:27] encoded transactions of shape [307457/401] imported\n"
     ]
    }
   ],
   "source": [
    "# import original and encoded transactions\n",
    "ori_dataset = pd.read_csv(\"./data/transactions.csv\", sep=\",\", header=0, encoding=\"utf-8\")\n",
    "enc_dataset = pd.read_csv(\"./data/enc_transactions.csv\", sep=\",\", header=0, encoding=\"utf-8\").astype(float)\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "print(\"[LOG {}] encoded transactions of shape [{}/{}] imported\".format(str(now), str(enc_dataset.shape[0]), str(enc_dataset.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [\"AccountID_Key\", \"CurrencyCode_Key\", \"TaxCode_Key\", \"CompanyKey_Key\", \"ShipToCountry_Key\", \"ShipFromCountry_Key\"]\n",
    "ranges = [0, 62+1, 121+1, 183+1, 234+1, 349+1, 400+1]\n",
    "\n",
    "# init training results\n",
    "columns = [\"timestamp\", \"node\", \"seed\", \"architecture\", \"epoch\", \"rec_loss\", \"roc_auc\", \"anomalies\", \"normalies\", \"anomalies_s\", \"normalies_s\", \"max_threshold\", \"max_tpr_s\", \"max_fpr_s\", \"precision\", \"recall\", \"f1_score\", \"fpr\", \"tpr\", \"thresholds\"]\n",
    "evaluations = [\"err_\" + str(element) for element in range(0, (len(features))+1)]\n",
    "columns.extend(evaluations)\n",
    "evaluations = [\"ano_c1_\" + str(element) for element in range(0, (len(features))+1)]\n",
    "columns.extend(evaluations)\n",
    "evaluations = [\"ano_c2_\" + str(element) for element in range(0, (len(features))+1)]\n",
    "columns.extend(evaluations)\n",
    "evaluation_results = pd.DataFrame(columns=columns)\n",
    "\n",
    "# convert to pytorch tensor - none cuda enabled\n",
    "torch_dataset = torch.from_numpy(enc_dataset.values).float()\n",
    "dataloader = DataLoader(torch_dataset, batch_size=mini_batch_size, shuffle=False, num_workers=0)\n",
    "# set num_workers to zero to retreive deterministic results\n",
    "\n",
    "# determine if CUDA is available at compute node\n",
    "if (torch.backends.cudnn.version() != None) and (use_cuda == True):\n",
    "\n",
    "    dataloader = DataLoader(torch_dataset.cuda(), batch_size=mini_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. Network Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDo - Timur and Marco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20180124-15:56:39] epoch: [0001/0001], batch: 0100, loss: 0.0026184090\n",
      "[LOG TRAIN 20180124-15:56:41] epoch: [0001/0001], batch: 0200, loss: 0.0029546609\n",
      "[LOG TRAIN 20180124-15:56:43] epoch: [0001/0001], batch: 0300, loss: 0.0017882250\n",
      "[LOG TRAIN 20180124-15:56:45] epoch: [0001/0001], batch: 0400, loss: 0.0011323976\n",
      "[LOG TRAIN 20180124-15:56:47] epoch: [0001/0001], batch: 0500, loss: 0.0014175044\n",
      "[LOG TRAIN 20180124-15:56:50] epoch: [0001/0001], batch: 0600, loss: 0.0020317647\n",
      "[LOG TRAIN 20180124-15:56:53] epoch: [0001/0001], batch: 0700, loss: 0.0029863003\n",
      "[LOG TRAIN 20180124-15:56:57] epoch: [0001/0001], batch: 0800, loss: 0.0012323590\n",
      "[LOG TRAIN 20180124-15:57:00] epoch: [0001/0001], batch: 0900, loss: 0.0038964848\n",
      "[LOG TRAIN 20180124-15:57:03] epoch: [0001/0001], batch: 1000, loss: 0.0015858796\n",
      "[LOG TRAIN 20180124-15:57:06] epoch: [0001/0001], batch: 1100, loss: 0.0025408012\n",
      "[LOG TRAIN 20180124-15:57:09] epoch: [0001/0001], batch: 1200, loss: 0.0017881792\n",
      "[LOG TRAIN 20180124-15:57:12] epoch: [0001/0001], batch: 1300, loss: 0.0056889043\n",
      "[LOG TRAIN 20180124-15:57:15] epoch: [0001/0001], batch: 1400, loss: 0.0030950278\n",
      "[LOG TRAIN 20180124-15:57:18] epoch: [0001/0001], batch: 1500, loss: 0.0016634385\n",
      "[LOG TRAIN 20180124-15:57:21] epoch: [0001/0001], batch: 1600, loss: 0.0000428326\n",
      "[LOG TRAIN 20180124-15:57:25] epoch: [0001/0001], batch: 1700, loss: 0.0014941720\n",
      "[LOG TRAIN 20180124-15:57:31] epoch: [0001/0001], batch: 1800, loss: 0.0001239985\n",
      "[LOG TRAIN 20180124-15:57:35] epoch: [0001/0001], batch: 1900, loss: 0.0014837544\n",
      "[LOG TRAIN 20180124-15:57:38] epoch: [0001/0001], batch: 2000, loss: 0.0015926077\n",
      "[LOG TRAIN 20180124-15:57:41] epoch: [0001/0001], batch: 2100, loss: 0.0023237620\n",
      "[LOG TRAIN 20180124-15:57:45] epoch: [0001/0001], batch: 2200, loss: 0.0004138105\n",
      "[LOG TRAIN 20180124-15:57:49] epoch: [0001/0001], batch: 2300, loss: 0.0002441822\n",
      "[LOG TRAIN 20180124-15:57:52] epoch: [0001/0001], batch: 2400, loss: 0.0004624868\n",
      "[LOG TRAIN 20180124-15:57:55] epoch: [0001/0001], batch: 2500, loss: 0.0000502754\n",
      "[LOG TRAIN 20180124-15:57:58] epoch: [0001/0001], batch: 2600, loss: 0.0000443095\n",
      "[LOG TRAIN 20180124-15:58:01] epoch: [0001/0001], batch: 2700, loss: 0.0001989982\n",
      "[LOG TRAIN 20180124-15:58:05] epoch: [0001/0001], batch: 2800, loss: 0.0000914283\n",
      "[LOG TRAIN 20180124-15:58:08] epoch: [0001/0001], batch: 2900, loss: 0.0001179544\n",
      "[LOG TRAIN 20180124-15:58:11] epoch: [0001/0001], batch: 3000, loss: 0.0004702709\n"
     ]
    }
   ],
   "source": [
    "# init deterministic seed\n",
    "seed_value = 1234 #4444 #3333 #2222 #1111 #1234\n",
    "rd.seed(seed_value) # set random seed\n",
    "np.random.seed(seed_value) # set numpy seed\n",
    "torch.manual_seed(seed_value) # set pytorch seed CPU\n",
    "torch.cuda.manual_seed(seed_value) # set pytorch seed GPU\n",
    "\n",
    "# init training parameters\n",
    "num_epochs = 1\n",
    "mini_batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# define optimization criterion and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "# train autoencoder model\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # init mini batch counter\n",
    "    mini_batch_count = 0\n",
    "\n",
    "    # determine if CUDA is available at compute node\n",
    "    if (torch.backends.cudnn.version() != None) and (use_cuda == True):\n",
    "\n",
    "        # set all networks / models in CPU mode\n",
    "        encoder.cuda()\n",
    "        decoder.cuda()\n",
    "\n",
    "    # set networks in training mode (apply dropout when needed)\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    for mini_batch_data in dataloader:\n",
    "\n",
    "        # increase mini batch counter\n",
    "        mini_batch_count += 1\n",
    "\n",
    "        # convert mini batch to torch variable\n",
    "        mini_batch_torch = autograd.Variable(mini_batch_data)\n",
    "\n",
    "        # =================== forward pass =====================\n",
    "\n",
    "        # run forward pass\n",
    "        z_representation = encoder(mini_batch_torch) # encode mini-batch data\n",
    "        mini_batch_reconstruction = decoder(z_representation) # decode mini-batch data\n",
    "\n",
    "        # determine reconstruction loss\n",
    "        reconstruction_loss = criterion(mini_batch_reconstruction, mini_batch_torch)\n",
    "\n",
    "        # =================== backward pass ====================\n",
    "\n",
    "        # reset graph gradients\n",
    "        decoder_optimizer.zero_grad()\n",
    "        encoder_optimizer.zero_grad()\n",
    "\n",
    "        # run backward pass\n",
    "        reconstruction_loss.backward()\n",
    "\n",
    "        # update network parameters\n",
    "        decoder_optimizer.step()\n",
    "        encoder_optimizer.step()\n",
    "\n",
    "        # =================== log ==============================\n",
    "\n",
    "        if mini_batch_count % 100 == 0:\n",
    "\n",
    "            # print mini batch reconstuction results\n",
    "            now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "            print('[LOG TRAIN {}] epoch: [{:04}/{:04}], batch: {:04}, loss: {:.10f}'.format(now, epoch + 1, num_epochs, mini_batch_count, reconstruction_loss.data[0]))\n",
    "\n",
    "# save trained encoder model file to disk\n",
    "encoder_model_name = \"{}_encoder_model.pth\".format(exp_timestamp)\n",
    "torch.save(encoder.state_dict(), os.path.join(\"models\", encoder_model_name))\n",
    "\n",
    "# save trained decoder model file to disk\n",
    "decoder_model_name = \"{}_decoder_model.pth\".format(exp_timestamp)\n",
    "torch.save(decoder.state_dict(), os.path.join(\"models\", decoder_model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06. Result Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load trained models\n",
    "encoder_trained = torch.load(os.path.join(\"models\", encoder_model_name))\n",
    "decoder_trained = torch.load(os.path.join(\"models\", decoder_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20180124-16:12:30] reconstruction loss: 0.0159976669\n"
     ]
    }
   ],
   "source": [
    "# convert mini batch to torch variable\n",
    "data = autograd.Variable(torch_dataset)\n",
    "\n",
    "# evaluate trained models\n",
    "reconstruction = decoder(encoder(data)) # autoencoder data\n",
    "\n",
    "# determine reconstruction loss\n",
    "reconstruction_loss = criterion(reconstruction, data)\n",
    "\n",
    "# =================== log evaluation measures ========================\n",
    "\n",
    "# print epoch reconstuction results\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "print('[LOG TRAIN {}] reconstruction loss: {:.10f}'.format(now, reconstruction_loss.data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07. Optional Excercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDo - Timur and Marco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08. Lab Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDo - Timur and Marco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09. Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDo - Timur and Marco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
