{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"./images/gtc_logo.png\", class=\"img-thumbnail\" align=\"left\", width=180, height=220>\n",
    "\n",
    "## <center>\"Detection of Anomalies in Financial Transactions using <br/> Deep Autoencoder Networks\" </center><br/> \n",
    "\n",
    "This GPU Technology Conference (GTC) 2018 lab was developed by Marco Schreyer and Timur Sattarov.\n",
    "The lab content is based on the following arXiv submission of the authors: https://arxiv.org/abs/1709.05254."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 01. Environment Setup and Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 01.1 Python Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Before we begin, let's verify that Python is working on your system. To do this, execute the cell block below by giving it focus (clicking on it with your mouse), and hitting Shift-Enter, or pressing the play button in the toolbar above. If all goes well, you should see some output returned below the grey cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('The answer should be forty-two: {}'.format(str(40+2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 01.2 Import Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# importing utilities\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# importing pytorch libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import autograd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# importing data science libraries\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 01.3 CUDNN / GPU Verficiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# print CUDNN backend version\n",
    "print('The CUDNN backend version: {}'.format(torch.backends.cudnn.version()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's execute the cell below to display information about the GPUs running on the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's execute the cell below to display information about the PyTorch version running on the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# print current PyTorch version\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "print('[LOG {}] PyTorch version: {}'.format(now, torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 02. Motivation and Lab Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.1 Fraud and Accounting Information Systems (AIS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The Association of Certified Fraud Examiners estimates in its Global Fraud Study 2016 [1] that the typical organization loses 5% of its annual revenues due to fraud. \n",
    "\n",
    ">The term \"fraud\" refers to \"the abuse of one's occupation for personal enrichment through the deliberate misuse of an organization's resources or assets\" [2]. \n",
    "\n",
    "A similar study, conducted by the auditors of PwC, revealed that nearly a quarter (22%) of respondents experienced losses of between \\$100,000 and \\$1 million [3]. The study also showed that financial statement fraud caused by far the greatest median loss of the surveyed fraud schemes.\n",
    "\n",
    "At the same time organizations accelerate the digitization and reconfiguration of business processes [4] affecting in particular Accounting Information Systems (AIS) or more general Enterprise Resource Planning (ERP) systems. Figure 01 depicts a hierarchical view of an Accounting Information System (AIS) recording process and journal entry information in designated database tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img align=\"middle\" style=\"max-width: 550px; height: auto\" src=\"images/accounting.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Figure 01:** Schematic and hierarchical view of an Accounting Information System (AIS) that records distinct layer of abstractions, namely (1) the business process, (2) the accounting and (3) technical journal entry information in designated database tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Steadily, these systems collect vast quantities of electronic evidence at an almost atomic level. This holds in particular for the journal entries of an organization recorded in its general ledger and sub-ledger accounts. SAP, one of the most prominent enterprise software providers, estimates that approx. 76% of the world's transaction revenue touches one of their ERP systems [5].\n",
    "\n",
    "In the context of forensic data analytics the data collected by such systems may contain valuable traces of a potential fraud scheme. Since perpetrators need to deviate from regular system usage or posting pattern in order to conduct fraud. Such deviations will be \"weakly\" recorded and reflected accordingly by a very limited number of \"anomalous\" financial transactions e.g. journal entries of an organization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.2 Classification of Transactional Anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "When conducting a detailed examination of real-world financial transactions, usually recorded in large-scaled ERP systems, two prevalent characteristics can be observed:\n",
    "\n",
    "- specific transactions attributes exhibit a high variety of distinct attribute values e.g. customer information, posted subledgers, amount information, and \n",
    "- the transactions exhibit strong dependencies between certain attribute values e.g. between customer informaiton and type of payment, posting type and general ledgers. \n",
    "\n",
    "Derived from this observation we distinguish two classes of anomalous financial transactions, namely global and local anomalies as illustrated in Figure 02 below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img align=\"middle\" style=\"max-width: 550px; height: auto\" src=\"images/anomalies.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Figure 02:** Illustrative example of global and local anomalies portrait in a feature space of the two transaction features posting amount (Feature 1) and posting positions (Feature 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "***Global anomalies***, are financial transactions that exhibit unusual or rare individual attribute values. These anomalies usually relate to highly skewed attributes e.g. seldom posting users, rarely used ledgers, or unusual posting times. Traditionally \"red-flag\" tests, performed by auditors during annual audits, are designed to capture those types of anomalies. However, such tests might result in a high volume of false positive alerts due to e.g. regular reverse postings, provisions and year-end adjustments usually associated with a low fraud risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "***Local anomalies***, are financial transactions that exhibit an unusual or rare combination of attribute values while the individual attribute values occur quite frequently e.g. unusual accounting records. This type of anomalies is significantly more difficult to detect since perpetrators intend to disguise their activities trying to imitate a regular behavior. As a result, such anomalies usually pose a high fraud risk since they might correspond to e.g. misused user accounts, irregular combinations of general ledger accounts and posting keys that don't follow usual a usual activity pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.3 Lab Objective and Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The main objective of this lab is to provide you a deep learning (DL) based methodology that can be beneficial to the complex detection of fraudulent activities in financial datasets. \n",
    "\n",
    "We will walk you through a use case of how a special type of deep neural networks, usually referred to as autoencoder neural networks (AENN), can be trained to learn a compressed but lossy model of regular transactions and their underlying posting pattern. Imposing a strong regularization onto the networks hidden layers limits the networks' ability to memorize the characteristics of anomalous journal entries. Once the training process is completed, the network will be able to reconstruct regular journal entries, while failing to do so for the anomalous ones.\n",
    "\n",
    "Please note, that this lab is not a complete nor comprehensive forensic data analysis approach or fraud examination strategy. Rather, it shows how AENN can be applied to detect anomalous records. The code provided in this lab can be repurposed or adopted to detect anomalous records in a variety of financial datasets. The detected records might serve as a starting point for a more detailed and substantive examination by auditors or compliance personel. \n",
    "\n",
    "It is assumed that you are familiar with the general concepts of deep neural networks (DNN), GPUs,  PyTorch, and Python. For more information on DNN, GPUs, and PyTorch, please check the relevant labs in DLI. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3. Autoencoder Neural Networks (AENNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this section, we will cover the major building blocks and the specifc network structure of deep autoencoder neural networks (AENNs) as well as an exemplary implementation using the open source machine learning libary PyTorch. The objective of this section is to familiarize with the underlying idea and concepts of building a deep AENN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.1 Autoencoder Neural Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "AENNs or replicator neural network are a variant of general feed-forward neural networks that have been initally introduced by xxx. AENNs comprise a specially designed network architecture that can be trained in a \"self-supervised\" manner to reconstruct its input. Figure XX illustrates a schematic view of an AENN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img align=\"middle\" style=\"max-width: 600px; height: auto\" src=\"images/autoencoder.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Figure XX:** Schematic view of an autoencoder network comprised of two non-linear mappings (fully connected feed forward neural networks) referred to as encoder $f_\\theta: \\mathbb{R}^{dx} \\mapsto \\mathbb{R}^{dz}$ and decoder $g_\\theta: \\mathbb{R}^{dz} \\mapsto \\mathbb{R}^{dy}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "AAEN can be interepreted as \"lossy\" data compression algorithms. They are \"lossy\" in a sense that the reconstructed outputs will be degraded compared to the original inputs. The difference between the original input and its reconstruction is referred to as reconstruction error. In general AENN encompass three major building blocks:\n",
    "\n",
    "\n",
    "   1. an encoding mapping function $f_\\theta$, \n",
    "   2. a decoding mapping function $g_\\theta$, \n",
    "   3. and a loss function $\\mathcal{L_{\\theta}}$.\n",
    "\n",
    "Most commonly the encoder and the decoder mapping functions are of symmetrical architecture consisting of several layers of neurons followed by a nonlinear function and shared parameters θ. The encoder mapping $f_\\theta(\\cdot)$ maps an input vector $x^i$ to compressed representation $z^i$ referred to as latent space $Z$. This hidden representation $z^i$ is then mapped back by the decoder $g_\\theta(\\cdot)$ to a re-constructed vector $x^i$ of the original input space. Formally, the nonlinear mappings of the encoder and the decoder can be defined by:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<center>$f_\\theta(x^i) = s(Wx^i + b)$, and $g_\\theta(z^i) = s′(W′z^i + d)$,</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "where $s$ and $s′$ denote a non-linear activations with model parameters $\\theta = \\{W, b, W', d\\}$, $W \\in \\mathbb{R}^{d_x \\times d_z}, W' \\in \\mathbb{R}^{d_z \\times d_y}$ are weight matrices and $b \\in \\mathbb{R}^{dx}$, $d \\in \\mathbb{R}^{dz}$ are the offset bias vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.2 Autoencoder Neural Network Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In an attempt to achieve $x^{i} \\approx \\hat{x}^{i}$ the autoencoder neural network can be trained to learn a set of encoder-decoder model parameters $\\theta$ that minimize the dissimilarity of a given journal entry $x^{i}$ and its reconstruction $\\hat{x}^{i} = g_\\theta(f_\\theta(x^{i}))$ as faithfully as possible. Thereby, the training objective is to learn a set of optimal shared encoder-decoder model parameters $\\theta^*$ that optimizes $\\arg\\min_{\\theta} \\|X - g_\\theta(f_\\theta(X))\\|$ over all journal entries $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To achieve this optimization objective one typically minimizes a loss function $\\mathcal{L_{\\theta}}$ as part of the network training. In this lab we use the mean squared error (MSE) reconstruction loss, defined by:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<center>$\\mathcal{L^{MSE}_{\\theta}}(x^{i};\\hat{x}^{i}) = \\frac{1}{k} \\sum_{j=1}^{k}{(x^{i}_{j} - \\hat{x}^{i}_{j})}^2$,</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "for a set of $n$-journal entries $x^{i}$, $i=1,...,n$ and their respective reconstructions $\\hat{x}^{i}$ over all journal entry attributes $j=1,...,k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.3 Autoencoder Neural Network Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, let's start the AENN implementation by first implementing the encoder network using PyTorch. For the encoder network model we aim to implement an architecture consisting of six fully-connected layers (FCL) specified by \"128-64-32-16-8-3\", meaning the first layer consists of 128 neurons, the second layer of 64 neurons and the subsequent layers of 32, 16, 8 and 3 neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In order to speed up training convergence and to avoid \"dying ReLUs\" we use Leaky ReLUs as non-linear activation functions. Finally, we also apply droupout with a probability of 20% for each neuron to be set to zero at a forward pass to prevent the network from overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# implementation of the encoder network\n",
    "class encoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(encoder, self).__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.0, inplace=True)\n",
    "\n",
    "        # specify layer 1 - in 186, out 128\n",
    "        self.encoder_L1 = nn.Linear(186, 128, bias=True) # add linearity \n",
    "        nn.init.xavier_uniform(self.encoder_L1.weight) # init weights according to [todo]\n",
    "        self.encoder_R1 = nn.LeakyReLU(negative_slope=0.4, inplace=True) # add non-linearity according to [todo]\n",
    "\n",
    "        # specify layer 2 - in 128, out 64\n",
    "        self.encoder_L2 = nn.Linear(128, 64, bias=True)\n",
    "        nn.init.xavier_uniform(self.encoder_L2.weight)\n",
    "        self.encoder_R2 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify layer 3 - in 64, out 32\n",
    "        self.encoder_L3 = nn.Linear(64, 32, bias=True)\n",
    "        nn.init.xavier_uniform(self.encoder_L3.weight)\n",
    "        self.encoder_R3 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify layer 3 - in 32, out 16\n",
    "        self.encoder_L4 = nn.Linear(32, 16, bias=True)\n",
    "        nn.init.xavier_uniform(self.encoder_L4.weight)\n",
    "        self.encoder_R4 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify layer 3 - in 16, out 8\n",
    "        self.encoder_L5 = nn.Linear(16, 8, bias=True)\n",
    "        nn.init.xavier_uniform(self.encoder_L5.weight)\n",
    "        self.encoder_R5 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify layer 3 - in 8, out 3\n",
    "        self.encoder_L6 = nn.Linear(8, 3, bias=True)\n",
    "        nn.init.xavier_uniform(self.encoder_L6.weight)\n",
    "        self.encoder_R6 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # define forward pass through the network\n",
    "        x = self.encoder_R1(self.dropout(self.encoder_L1(x)))\n",
    "        x = self.encoder_R2(self.dropout(self.encoder_L2(x)))\n",
    "        x = self.encoder_R3(self.dropout(self.encoder_L3(x)))\n",
    "        x = self.encoder_R4(self.dropout(self.encoder_L4(x)))\n",
    "        x = self.encoder_R5(self.dropout(self.encoder_L5(x)))\n",
    "        x = self.encoder_R6(self.encoder_L6(x)) # don't apply dropout to the AE bottleneck\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, we are now ready to initialize the network locally or using CUDNN (to utilize potential available GPUs for computation). Once initialized let's print and review the implemented network architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# init training network classes / architectures\n",
    "encoder_train = encoder()\n",
    "\n",
    "# push to cuda if cudnn is available\n",
    "if (torch.backends.cudnn.version() != None and USE_CUDA == True):\n",
    "    encoder_train = encoder().cuda()\n",
    "\n",
    "# print the initialized architectures\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "print('[LOG {}] encoder architecture:\\n\\n{}\\n'.format(now, encoder_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's complete the AENN implementation by implementing the decoder network. The design of the decoder network architecture also consists of six fully-connected layers (FCL) and is intended to mirror the encoder network architecture by a layerwise inversion \"8-16-32-64-128-186\" of the encoder layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# implementation of the decoder network\n",
    "class decoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(decoder, self).__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.0, inplace=True)\n",
    "\n",
    "        # specify layer 1 - in 3, out 8\n",
    "        self.decoder_L1 = nn.Linear(3, 8, bias=True) # add linearity \n",
    "        nn.init.xavier_uniform(self.decoder_L1.weight)  # init weights according to [todo]\n",
    "        self.decoder_R1 = nn.LeakyReLU(negative_slope=0.4, inplace=True) # add non-linearity according to [todo]\n",
    "\n",
    "        # specify layer 1 - in 8, out 16\n",
    "        self.decoder_L2 = nn.Linear(8, 16, bias=True)\n",
    "        nn.init.xavier_uniform(self.decoder_L2.weight)\n",
    "        self.decoder_R2 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify layer 1 - in 16, out 32\n",
    "        self.decoder_L3 = nn.Linear(16, 32, bias=True)\n",
    "        nn.init.xavier_uniform(self.decoder_L3.weight)\n",
    "        self.decoder_R3 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify layer 1 - in 32, out 64\n",
    "        self.decoder_L4 = nn.Linear(32, 64, bias=True)\n",
    "        nn.init.xavier_uniform(self.decoder_L4.weight)\n",
    "        self.decoder_R4 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify layer 1 - in 64, out 128\n",
    "        self.decoder_L5 = nn.Linear(64, 128, bias=True)\n",
    "        nn.init.xavier_uniform(self.decoder_L5.weight)\n",
    "        self.decoder_R5 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify layer 1 - in 128, out 186\n",
    "        self.decoder_L6 = nn.Linear(128, 186, bias=True)\n",
    "        nn.init.xavier_uniform(self.decoder_L6.weight)\n",
    "        self.decoder_R6 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # define forward pass through the network\n",
    "        x = self.decoder_R1(self.dropout(self.decoder_L1(x)))\n",
    "        x = self.decoder_R2(self.dropout(self.decoder_L2(x)))\n",
    "        x = self.decoder_R3(self.dropout(self.decoder_L3(x)))\n",
    "        x = self.decoder_R4(self.dropout(self.decoder_L4(x)))\n",
    "        x = self.decoder_R5(self.dropout(self.decoder_L5(x)))\n",
    "        x = self.decoder_R6(self.decoder_L6(x)) # don't apply dropout to the AE output\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's again initialize the implemented network and correspondingly convince ourselves that it was successfully initialized by printing and reviewing the initialized architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# init training network classes / architectures\n",
    "decoder_train = decoder()\n",
    "\n",
    "# push to cuda if cudnn is available\n",
    "if (torch.backends.cudnn.version() != None):\n",
    "    decoder_train = decoder().cuda()\n",
    "    \n",
    "# print the initialized architectures\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "print('[LOG {}] decoder architecture:\\n\\n{}\\n'.format(now, decoder_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 04. Financial Fraud Detection Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The dataset is extracted from Kaggle datasets repository at the following link: \n",
    "https://www.kaggle.com/ntnu-testimon/paysim1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "ori_dataset = pd.read_csv(\"./data/PS_20174392719_1491204439457_log.csv\", sep=\",\", header=0, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ori_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# dimension of data\n",
    "ori_dataset.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot \"step\" and \"type\" attributes\n",
    "sns.set()\n",
    "fig, ax =plt.subplots(1,2)\n",
    "fig.set_figwidth(15)\n",
    "sns.distplot(ori_dataset['step'], kde=False, bins=100, ax=ax[0])\n",
    "sns.countplot(x=ori_dataset['type'], ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# let's have a look what \"type\" do fraudulent transactions possess\n",
    "ori_dataset[ori_dataset['isFraud'] == 1]['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# we select a subset of \"type\": \"transfer\" (\"cash-out\" may be selected for optional excercise)\n",
    "ori_subset = ori_dataset[ori_dataset['type'] == 'TRANSFER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# dimension of data\n",
    "ori_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot \"amount\" attribute and its log scale\n",
    "fig, ax =plt.subplots(1,2)\n",
    "fig.set_figwidth(15)\n",
    "sns.distplot(ori_subset['amount'], ax=ax[0])\n",
    "sns.distplot(ori_subset['amount'].apply(np.log), ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Preprocess numeric attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# select numeric attributes\n",
    "numeric_attr_names = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "epsilon = 1e-7\n",
    "\n",
    "# add a small epsilon to eliminate zero values from data for log scaling\n",
    "numeric_attr = ori_subset[numeric_attr_names] + epsilon\n",
    "numeric_attr = numeric_attr.apply(np.log)\n",
    "\n",
    "# normalize all numeric attribute to the range [0,1]\n",
    "numeric_attr = (numeric_attr - numeric_attr.min()) / (numeric_attr.max() - numeric_attr.min())\n",
    "\n",
    "# append 'isFraud' attribute\n",
    "numeric_attr['isFraud'] = ori_subset['isFraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot numeric attributes scaled under natural log\n",
    "if os.path.exists('./images/numeric_attr_pair_plot.png'):\n",
    "    display(Image('./images/numeric_attr_pair_plot.png'))\n",
    "else:\n",
    "    sns.pairplot(data=numeric_attr, vars=numeric_attr_names, hue='isFraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# number of distinct values possessed by 'nameOrig'\n",
    "ori_subset['nameOrig'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# if we select first 2 or 3 characters\n",
    "nameOrig_slice_2 = ori_subset['nameOrig'].str.slice(0, 2)\n",
    "nameOrig_slice_3 = ori_subset['nameOrig'].str.slice(0, 3)\n",
    "\n",
    "nameDest_slice_2 = ori_subset['nameDest'].str.slice(0, 2)\n",
    "nameDest_slice_3 = ori_subset['nameDest'].str.slice(0, 3)\n",
    "\n",
    "fig, ax =plt.subplots(1,2)\n",
    "fig.set_figwidth(20)\n",
    "sns.countplot(x=nameOrig_slice_2, ax=ax[0])\n",
    "sns.countplot(x=nameOrig_slice_3, ax=ax[1])\n",
    "# g.set_xticklabels(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# select categorical attributes\n",
    "ori_subset_categ = pd.concat([ori_subset['type'], nameOrig_slice_3, nameDest_slice_3], \n",
    "                             axis = 1,\n",
    "                             names = ['type', 'nameOrig', 'nameDest'])\n",
    "# select numeric attributes\n",
    "ori_subset_numeric = numeric_attr.drop('isFraud', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.x \"One-Hot\" Encoded Feature Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"middle\" style=\"max-width: 450px; height: auto\" src=\"images/encoding.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# transform categorcal attributes into a sparse representation uning one-hot transformation\n",
    "ori_subset_categ_transformed = pd.get_dummies(ori_subset_categ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# join categorical and numeric subsets\n",
    "ori_subset_transformed = pd.concat([ori_subset_categ_transformed, ori_subset_numeric],\n",
    "                                   axis = 1)\n",
    "ori_subset_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# prepate the dataset for pytorch loader\n",
    "torch_dataset = torch.from_numpy(ori_subset_transformed.values).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 05. Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "ToDo - Timur and Marco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# init deterministic seed\n",
    "seed_value = 1234 #4444 #3333 #2222 #1111 #1234\n",
    "rd.seed(seed_value) # set random seed\n",
    "np.random.seed(seed_value) # set numpy seed\n",
    "torch.manual_seed(seed_value) # set pytorch seed CPU\n",
    "# torch.cuda.manual_seed(seed_value) # set pytorch seed GPU\n",
    "\n",
    "# init training parameters\n",
    "num_epochs = 50\n",
    "mini_batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# convert to pytorch tensor - none cuda enabled\n",
    "dataloader = DataLoader(torch_dataset, batch_size=mini_batch_size, shuffle=True, num_workers=0)\n",
    "# set num_workers to zero to retreive deterministic results\n",
    "\n",
    "# determine if CUDA is available at compute node\n",
    "if (torch.backends.cudnn.version() != None):\n",
    "\n",
    "    dataloader = DataLoader(torch_dataset.cuda(), batch_size=mini_batch_size, shuffle=True)\n",
    "\n",
    "# define optimization criterion and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "encoder_optimizer = torch.optim.Adam(encoder_train.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = torch.optim.Adam(decoder_train.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to start training the model, name it `GAN-MNIST` and click `Create`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train autoencoder model\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # init mini batch counter\n",
    "    mini_batch_count = 0\n",
    "\n",
    "    # determine if CUDA is available at compute node\n",
    "    if (torch.backends.cudnn.version() != None) and (use_cuda == True):\n",
    "\n",
    "        # set all networks / models in CPU mode\n",
    "        encoder_train.cuda()\n",
    "        decoder_train.cuda()\n",
    "\n",
    "    # set networks in training mode (apply dropout when needed)\n",
    "    encoder_train.train()\n",
    "    decoder_train.train()\n",
    "\n",
    "    for mini_batch_data in dataloader:\n",
    "\n",
    "        # increase mini batch counter\n",
    "        mini_batch_count += 1\n",
    "\n",
    "        # convert mini batch to torch variable\n",
    "        mini_batch_torch = autograd.Variable(mini_batch_data)\n",
    "\n",
    "        # =================== forward pass =====================\n",
    "\n",
    "        # run forward pass\n",
    "        z_representation = encoder_train(mini_batch_torch) # encode mini-batch data\n",
    "        mini_batch_reconstruction = decoder_train(z_representation) # decode mini-batch data\n",
    "\n",
    "        # determine reconstruction loss\n",
    "        reconstruction_loss = criterion(mini_batch_reconstruction, mini_batch_torch)\n",
    "\n",
    "        # =================== backward pass ====================\n",
    "\n",
    "        # reset graph gradients\n",
    "        decoder_optimizer.zero_grad()\n",
    "        encoder_optimizer.zero_grad()\n",
    "\n",
    "        # run backward pass\n",
    "        reconstruction_loss.backward()\n",
    "\n",
    "        # update network parameters\n",
    "        decoder_optimizer.step()\n",
    "        encoder_optimizer.step()\n",
    "\n",
    "        # =================== log ==============================\n",
    "\n",
    "        if mini_batch_count % 100 == 0:\n",
    "\n",
    "            # print mini batch reconstuction results\n",
    "            now = datetime.utcnow().strftime(\"%Y%m%d-%H_%M_%S\")\n",
    "            print('[LOG {}] training status, epoch: [{:04}/{:04}], batch: {:04}, loss: {:.10f}'.format(now, (epoch+1), num_epochs, mini_batch_count, reconstruction_loss.data[0]))\n",
    "\n",
    "    # save trained encoder model file to disk\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d-%H_%M_%S\")\n",
    "    encoder_model_name = \"{}_ep_{}_encoder_model.pth\".format(now, (epoch+1))\n",
    "    torch.save(encoder_train.state_dict(), os.path.join(\"./models\", encoder_model_name))\n",
    "\n",
    "    # save trained decoder model file to disk\n",
    "    decoder_model_name = \"{}_ep_{}_decoder_model.pth\".format(now, (epoch+1))\n",
    "    torch.save(decoder_train.state_dict(), os.path.join(\"./models\", decoder_model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 06. Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# specify trained models to be loaded\n",
    "encoder_model_name = \"20180215-14_09_36_ep_10_encoder_model.pth\"\n",
    "decoder_model_name = \"20180215-14_09_36_ep_10_decoder_model.pth\"\n",
    "\n",
    "# init training network classes / architectures\n",
    "encoder_eval = encoder()\n",
    "decoder_eval = decoder()\n",
    "\n",
    "# load trained models\n",
    "encoder_eval.load_state_dict(torch.load(os.path.join(\"models\", encoder_model_name)))\n",
    "decoder_eval.load_state_dict(torch.load(os.path.join(\"models\", decoder_model_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# convert encoded transactional data to torch Variable\n",
    "data = autograd.Variable(torch_dataset)\n",
    "\n",
    "# set networks in training mode (don't apply dropout)\n",
    "encoder_eval.eval()\n",
    "decoder_eval.eval()\n",
    "\n",
    "# reconstruct encoded transactional data\n",
    "reconstruction = decoder_eval(encoder_eval(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# determine reconstruction loss - all transactions\n",
    "reconstruction_loss_all = criterion(reconstruction, data)\n",
    "\n",
    "# print reconstruction loss - all transactions\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "print('[LOG {}] collected reconstruction loss of: {:06}/{:06} transactions'.format(now, reconstruction.size()[0], reconstruction.size()[0]))\n",
    "print('[LOG {}] reconstruction loss: {:.10f}'.format(now, reconstruction_loss_all.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# init binary cross entropy errors\n",
    "reconstruction_loss_transaction = np.zeros(reconstruction.size()[0])\n",
    "\n",
    "# iterate over all detailed reconstructions\n",
    "for i in range(0, reconstruction.size()[0]):\n",
    "\n",
    "    # determine reconstruction loss - individual transactions\n",
    "    reconstruction_loss_transaction[i] = criterion(reconstruction[i], data[i]).data[0]\n",
    "\n",
    "    if(i % 100000 == 0):\n",
    "\n",
    "        ### print conversion summary\n",
    "        now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "        print('[LOG {}] collected individial reconstruction loss of: {:06}/{:06} transactions'.format(now, i, reconstruction.size()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# prepare plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plot_data = np.column_stack((np.arange(len(reconstruction_loss_transaction)), \n",
    "                             reconstruction_loss_transaction))\n",
    "\n",
    "regular_data = plot_data[ori_subset.isFraud == 0]\n",
    "fraud_data = plot_data[ori_subset.isFraud == 1]\n",
    "\n",
    "# plot reconstruction error scatter plot\n",
    "ax.scatter(regular_data[:, 0], regular_data[:, 1], c='C0', alpha=0.4, marker=\"o\") # plot regular transactions\n",
    "ax.scatter(fraud_data[:, 0], fraud_data[:, 1], c='C1', marker=\"^\") # plot fraudulent transactions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 7. Optional Excercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Please read ahead and only come back to these optional exercises if time permits.\n",
    "\n",
    "**1. Train from scratch** [15 mins]\n",
    "\n",
    "First, change the # of epochs to 10 in the above cell. Second, put the starting learning rate back to **0.001**. Third, comment out the two line where the pre-trained model is loaded (under \"Restore latest checkpoint\"). Then re-run everything using Kernel -> Restart & Run All. \n",
    "\n",
    "**2. What would happen if we remove one of the fully-connected layers?** [15 mins]\n",
    "\n",
    "We designed a specific model for the lab because experiments show that the structure depicted in Figure 4 provided the best accuracy. Let's see what kind of correlation we would get if remove one of the LSTM cells. First, follow all the instructions for training from scratch if you haven't already. Then open the [dnn.py](../edit/dnn.py) and replace the number \"2\" in line 8 with \"1\". \n",
    "\n",
    "File->Save for dnn.py \n",
    "\n",
    "Re-run the whole notebook using Kernel->Restart & Run All menu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 8. Lab Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "ToDo - Timur and Marco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 9. Post-Lab Excercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We recommend you to try the following steps after the lab:\n",
    "\n",
    "1. Try to implement shallow and deeper autoencoder architectures (by removing and adding an arbitrary number of fully-connected layers). Analyze the performance in terms of training time and reconstruction error.\n",
    "\n",
    "2. Try using other dimensionality reduction techniques such as principal component analysis, non-negative matrix factorization or sparse coding and compare the detected anomalies with the ones detected by the autoencoder.\n",
    "\n",
    "3. Try using other autoencoder architectures such as denoising or adversarial autoencoder and compare the results with the vanilla autoencoder architecture implemented above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## XX. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "[1] ACFE, Report to the Nations on Occupational Fraud and Abuse, The 2016 Global Fraud Study, Association of Certified Fraud Examiners (ACFE), 2016.\n",
    "\n",
    "[2] J. T. Wells, Corporate Fraud Handbook: Prevention and Detection, John Wiley & Sons, 2017.\n",
    "\n",
    "[3] PwC, Adjusting the Lens on Economic Crime, The Global Economic Crime Survey 2016, PricewaterhouseCoopers LLP, 2016.\n",
    "\n",
    "[4] S. Markovitch, P. Willmott, Accelerating the digitization of business processes, McKinsey & Company (2014) 1–5.\n",
    "\n",
    "[5] SAP, SAP Global Corporate Affairs, Corporate Factsheet 2017, 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
